{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import jieba\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchtext import data\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# hyper parameters\n",
    "\n",
    "STR_MAXLEN = 30\n",
    "BATCH_SIZE = 256\n",
    "DEVICE = torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")\n",
    "EMBED_DIM = 300\n",
    "HIDDEN_DIM = 100\n",
    "DEEP_LAYERS = [200]\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHES = 80\n",
    "DECAY_STEP = 2\n",
    "DECAY_GAMMA = 0.99\n",
    "CLASS_WEIGHT = [0.6116, 2.7397]\n",
    "def print_flush(data, args=None):\n",
    "    if args == None:\n",
    "        print(data)\n",
    "    else:\n",
    "        print(data, args)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def pad_seq(seq, max_length):\n",
    "    length = len(seq[0])\n",
    "    pad_leng = 0 if length > max_length else (max_length-length)\n",
    "    if pad_leng == 0:\n",
    "        seq = seq[:, :max_length]\n",
    "    else:\n",
    "        seq = torch.cat([seq, torch.ones(len(seq), pad_leng).long().to(DEVICE)], dim=1)\n",
    "    return seq\n",
    "\n",
    "def wordlist_to_matrix(pretrain_path, wordlist, device, dim=300):\n",
    "    word_vec = {}\n",
    "    with open(pretrain_path, encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            line = line.split(' ')\n",
    "            word = line[0]\n",
    "            vec = line[1:]\n",
    "            word_vec[word] = np.array(vec, dtype=float)\n",
    "    word_vec_list = []\n",
    "    oov = 0\n",
    "    oov_words = []\n",
    "    for idx, word in enumerate(wordlist):\n",
    "        try:\n",
    "            vector = np.array(word_vec[word], dtype=float).reshape(1,dim)\n",
    "        except:\n",
    "            oov += 1\n",
    "            oov_words.append(word)\n",
    "            # print(word)\n",
    "            vector = np.random.rand(1, dim)\n",
    "        word_vec_list.append(torch.from_numpy(vector))\n",
    "    wordvec_matrix = torch.cat(word_vec_list)\n",
    "    print(\"Load embedding finished.\")\n",
    "    print(\"Total words count: {}, oov count: {}.\".format(wordvec_matrix.size()[0], oov))\n",
    "    return wordvec_matrix if device == -1 else wordvec_matrix.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process raw data...\n",
      "Building vocabulary Finished.\n",
      "Load embedding finished.\n",
      "Total words count: 1517, oov count: 8.\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [txt for txt in text]\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, iter_columns):\n",
    "        self.dl, self.iter_columns = dl, iter_columns  # we pass in the list of attributes for x &amp;amp;amp;amp;lt;g class=\"gr_ gr_3178 gr-alert gr_spell gr_inline_cards gr_disable_anim_appear ContextualSpelling ins-del\" id=\"3178\" data-gr-id=\"3178\"&amp;amp;amp;amp;gt;and y&amp;amp;amp;amp;lt;/g&amp;amp;amp;amp;gt;\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield (getattr(batch, attr) for attr in self.iter_columns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "print_flush('process raw data...')\n",
    "TEXT = data.Field(sequential=True, use_vocab=True, eos_token='<EOS>', init_token='<BOS>',pad_token='<PAD>', \n",
    "                  batch_first=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "tv_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"txt1\", TEXT), (\"txt2\", TEXT),\n",
    "                 (\"label\", LABEL)]\n",
    "\n",
    "train = data.TabularDataset(path='../datasets/train.csv', format='csv', skip_header=True, fields=tv_datafields)\n",
    "valid = data.TabularDataset(path='../datasets/valid.csv', format='csv', skip_header=True, fields=tv_datafields)\n",
    "\n",
    "TEXT.build_vocab(train, valid, min_freq=3)\n",
    "print_flush('Building vocabulary Finished.')\n",
    "matrix = wordlist_to_matrix('../datasets/pretrain_embedding/pretrain_full_emb.txt', TEXT.vocab.itos, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare data done!\n"
     ]
    }
   ],
   "source": [
    "train_iter = data.BucketIterator(dataset=train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.txt1) + len(x.txt2), shuffle=False, device=DEVICE, repeat=False)\n",
    "valid_iter = data.Iterator(dataset=valid, batch_size=BATCH_SIZE, device=DEVICE, shuffle=False, repeat=False)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, [\"txt1\", \"txt2\", \"label\"])\n",
    "valid_dl = BatchWrapper(valid_iter, [\"txt1\", \"txt2\", \"label\"])\n",
    "\n",
    "print_flush('prepare data done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    '''\n",
    "    convolution layer for abcnn\n",
    "    Attributes\n",
    "    ----------\n",
    "    inception : bool\n",
    "        whether use inception module\n",
    "    '''\n",
    "    def __init__(self, isAbcnn2, sentence_length, filter_width, filter_height, filter_channel, inception):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        if inception:\n",
    "            self.model = InceptionModule(1 if isAbcnn2 else 2, sentence_length, filter_width, filter_height, filter_channel)\n",
    "        else:\n",
    "            self.model = convolution(1 if isAbcnn2 else 2, filter_width, filter_height, filter_channel, filter_width-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        1. convlayer\n",
    "            size (batch_size, filter_channel, width, 1)\n",
    "        2. transpose\n",
    "            size (batch_size, 1, width, filter_channel)\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 4-D torch Tensor\n",
    "            size (batch_size, 1, width, height)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        output : 4-D torch Tensor\n",
    "            size (batch_size, 1, width, filter_channel)\n",
    "        '''\n",
    "        output = self.model(x)\n",
    "        output = output.permute(0, 3, 2, 1)\n",
    "        return output\n",
    "\n",
    "def cosine_similarity(x1, x2):\n",
    "    '''compute cosine similarity between x1 and x2\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, x2 : 2-D torch Tensor\n",
    "        size (batch_size, 1)\n",
    "    Returns\n",
    "    -------\n",
    "    distance : 2-D torch Tensor\n",
    "        similarity result of size (batch_size, 1)\n",
    "    '''\n",
    "    return F.cosine_similarity(x1, x2).unsqueeze(1)\n",
    "\n",
    "def manhattan_distance(x1, x2):\n",
    "    '''compute manhattan distance between x1 and x2 (not in paper)\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, x2 : 2-D torch Tensor\n",
    "        size (batch_size, 1)\n",
    "    Returns\n",
    "    -------\n",
    "    distance : 2-D torch Tensor\n",
    "        similarity result of size (batch_size, 1)\n",
    "    '''\n",
    "    return torch.div(torch.norm((x1 - x2), 1, 1, keepdim=True), x1.size()[1])\n",
    "\n",
    "def convolution(in_channel, filter_width, filter_height, filter_channel, padding):\n",
    "    '''convolution layer\n",
    "    '''\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_channel, filter_channel, (filter_width, filter_height), stride=1, padding=(padding, 0)),\n",
    "        nn.BatchNorm2d(filter_channel),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "def attention_matrix(x1, x2, eps=1e-6):\n",
    "    '''compute attention matrix using match score\n",
    "    \n",
    "    1 / (1 + |x · y|)\n",
    "    |·| is euclidean distance\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, x2 : 4-D torch Tensor\n",
    "        size (batch_size, 1, sentence_length, h)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : 3-D torch Tensor\n",
    "        match score result of size (batch_size, sentence_length(for x2), sentence_length(for x1))\n",
    "    '''\n",
    "    eps = torch.tensor(eps).to(DEVICE)\n",
    "    one = torch.tensor(1.).to(DEVICE)\n",
    "    euclidean = (torch.pow(x1 - x2.permute(0, 2, 1, 3), 2).sum(dim=3) + eps).sqrt()\n",
    "    return (euclidean + one).reciprocal()\n",
    "\n",
    "class ApLayer(nn.Module):\n",
    "    '''column-wise averaging over all columns\n",
    "    '''\n",
    "\n",
    "    def __init__(self, pool_width, height):\n",
    "        super(ApLayer, self).__init__()\n",
    "        self.ap = nn.AvgPool2d((pool_width, 1), stride=1)\n",
    "        self.height = height\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        1. average pooling\n",
    "            x size (batch_size, 1, 1, height)\n",
    "        2. representation vector for the sentence\n",
    "            output size (batch_size, height)\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 4-D torch Tensor\n",
    "            convolution output of size (batch_size, 1, sentence_length, height)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        output : 2-D torch Tensor\n",
    "            representation vector of size (batch_size, height)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        return self.ap(x).view([-1, self.height])\n",
    "\n",
    "class WpLayer(nn.Module):\n",
    "    '''column-wise averaging over windows of w consecutive columns\n",
    "    Attributes\n",
    "    ----------\n",
    "    attention : bool\n",
    "        compute layer with attention matrix\n",
    "    '''\n",
    "    def __init__(self, sentence_length, filter_width, attention):\n",
    "        super(WpLayer, self).__init__()\n",
    "        self.attention = attention\n",
    "        if attention:\n",
    "            self.sentence_length = sentence_length\n",
    "            self.filter_width = filter_width\n",
    "        else:\n",
    "            self.wp = nn.AvgPool2d((filter_width, 1), stride=1)\n",
    "\n",
    "    def forward(self, x, attention_matrix=None):\n",
    "        '''\n",
    "        if attention\n",
    "            reweight the convolution output with attention matrix\n",
    "        else\n",
    "            average pooling\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 4-D torch Tensor\n",
    "            convolution output of size (batch_size, 1, sentence_length + filter_width - 1, height)\n",
    "        attention_matrix: 2-D torch Tensor\n",
    "            attention matrix between (convolution output x1 and convolution output x2) of size (batch_size, sentence_length + filter_width - 1)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        output : 4-D torch Tensor\n",
    "            size (batch_size, 1, sentence_length, height)\n",
    "        '''\n",
    "        if self.attention:\n",
    "            pools = []\n",
    "            attention_matrix = attention_matrix.unsqueeze(1).unsqueeze(3)\n",
    "            for i in range(self.sentence_length):\n",
    "                pools.append((x[:, :, i:i+self.filter_width, :] * attention_matrix[:, :, i:i+self.filter_width, :]).sum(dim=2, keepdim=True))\n",
    "\n",
    "            return torch.cat(pools, dim=2)\n",
    "        \n",
    "        else:\n",
    "            return self.wp(x)        \n",
    "    \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 and classname.find('Layer') == -1:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Abcnn1Portion(nn.Module):\n",
    "    '''Part of Abcnn1\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Abcnn1Portion, self).__init__()\n",
    "        self.batchNorm = nn.BatchNorm2d(2)\n",
    "        self.attention_feature_layer = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        '''\n",
    "        1. compute attention matrix\n",
    "            attention_m : size (batch_size, sentence_length, sentence_length)\n",
    "        2. generate attention feature map(weight matrix are parameters of the model to be learned)\n",
    "            x_attention : size (batch_size, 1, sentence_length, height)\n",
    "        3. stack the representation feature map and attention feature map\n",
    "            x : size (batch_size, 2, sentence_length, height)\n",
    "        4. batch norm(not in paper)\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1, x2 : 4-D torch Tensor\n",
    "            size (batch_size, 1, sentence_length, height)\n",
    "        Returns\n",
    "        -------\n",
    "        (x1, x2) : list of 4-D torch Tensor\n",
    "            size (batch_size, 2, sentence_length, height)\n",
    "        '''\n",
    "        attention_m = attention_matrix(x1, x2)\n",
    "#         print('attention matrix', attention_m)\n",
    "#         print('size', attention_m.size())\n",
    "        x1_attention = self.attention_feature_layer(attention_m.permute(0, 2, 1))\n",
    "#         print('x1 attention', x1_attention)\n",
    "#         print('size', x1_attention.size())\n",
    "\n",
    "        x1_attention = x1_attention.unsqueeze(1)\n",
    "        x1 = torch.cat([x1, x1_attention], 1)\n",
    "\n",
    "        x2_attention = self.attention_feature_layer(attention_m)\n",
    "        x2_attention = x2_attention.unsqueeze(1)\n",
    "        x2 = torch.cat([x2, x2_attention], 1)\n",
    "\n",
    "        x1 = self.batchNorm(x1)\n",
    "        x2 = self.batchNorm(x2)\n",
    "        \n",
    "        return (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Abcnn1(nn.Module):\n",
    "    '''\n",
    "    ABCNN1\n",
    "    1. ABCNN1\n",
    "    2. wide convolution\n",
    "    3. W-ap\n",
    "    Attributes\n",
    "    ----------\n",
    "    layer_size : int\n",
    "        the number of (abcnn1)\n",
    "    distance : function\n",
    "        cosine similarity or manhattan\n",
    "    abcnn : list of abcnn1\n",
    "    conv : list of convolution layer\n",
    "    wp : list of w-ap pooling layer\n",
    "    ap : list of pooling layer\n",
    "    fc : last linear layer(in paper use logistic regression)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, vocab, emb_dim, sentence_length, filter_width, filter_channel=50, layer_size=2, match='cosine', inception=True,  pretrain_embed=torch.tensor([]), ):\n",
    "        super(Abcnn1, self).__init__()\n",
    "        self.layer_size = layer_size\n",
    "        if match == 'cosine':\n",
    "            self.distance = cosine_similarity\n",
    "        else:\n",
    "            self.distance = manhattan_distance\n",
    "        self.word_embed = nn.Embedding(len(vocab), emb_dim, padding_idx=1)\n",
    "        if len(pretrain_embed) != 0:\n",
    "            self.word_embed.weight.data.copy_(pretrain_embed)\n",
    "        self.lstm_embed = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.abcnn = nn.ModuleList()\n",
    "        self.conv = nn.ModuleList()\n",
    "        self.ap = nn.ModuleList([ApLayer(sentence_length, emb_dim)])\n",
    "        self.wp = nn.ModuleList()\n",
    "        self.fc = nn.Linear(layer_size+1, 2)\n",
    "        torch.manual_seed(2018)\n",
    "        for i in range(layer_size):\n",
    "            self.abcnn.append(Abcnn1Portion(sentence_length, emb_dim if i == 0 else filter_channel))\n",
    "            self.conv.append(ConvLayer(False, sentence_length, filter_width, emb_dim if i == 0 else filter_channel, filter_channel, inception))\n",
    "            self.ap.append(ApLayer(sentence_length + filter_width - 1, filter_channel))\n",
    "            self.wp.append(WpLayer(sentence_length, filter_width, False))\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        '''\n",
    "        1. stack sentence vector similarity\n",
    "        2. for layer_size\n",
    "            abcnn1\n",
    "            convolution\n",
    "            stack sentence vector similarity\n",
    "            W-ap for next loop x1, x2\n",
    "        \n",
    "        3. concatenate similarity list\n",
    "            size (batch_size, layer_size + 1)\n",
    "        4. Linear layer\n",
    "            size (batch_size, 1)\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1, x2 : 4-D torch Tensor\n",
    "            size (batch_size, 1, width, emb_dim)\n",
    "        Returns\n",
    "        -------\n",
    "        output : 2-D torch Tensor\n",
    "            size (batch_size, 1)\n",
    "        '''\n",
    "        x1 = self.word_embed(x1)\n",
    "        x2 = self.word_embed(x2)\n",
    "        x1.unsqueeze_(1)\n",
    "        x2.unsqueeze_(1)\n",
    "        sim = []\n",
    "        sim.append(self.distance(self.ap[0](x1), self.ap[0](x2)))\n",
    "\n",
    "        for i in range(self.layer_size):\n",
    "            x1, x2 = self.abcnn[i](x1, x2)\n",
    "#             print('ap', self.conv[i](x1))\n",
    "#             print('size', self.conv[i](x1).size())\n",
    "            x1 = self.conv[i](x1)\n",
    "            x2 = self.conv[i](x2)\n",
    "            sim.append(self.distance(self.ap[i+1](x1), self.ap[i+1](x2)))\n",
    "#             print('ap',  self.wp[i](x1))\n",
    "#             print('size',  self.wp[i](x1).size())\n",
    "            x1 = self.wp[i](x1)\n",
    "            x2 = self.wp[i](x2)\n",
    "        sim_fc = torch.cat(sim, dim=1)\n",
    "        output = self.fc(sim_fc)\n",
    "        return F.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6f7a9a8ea683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbcnn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEMBED_DIM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTR_MAXLEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cosine'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDECAY_STEP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDECAY_GAMMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-b42141bed64d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vocab, emb_dim, sentence_length, filter_width, filter_channel, layer_size, match, inception, pretrain_embed)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrain_embed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrain_embed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embed_dim' is not defined"
     ]
    }
   ],
   "source": [
    "model = Abcnn1(TEXT.vocab.stoi, EMBED_DIM, STR_MAXLEN, 3,50, 2, 'cosine', False)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = StepLR(optimizer, step_size=DECAY_STEP, gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "batch number  337\n",
      "learning rate: 0.000676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:82: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 50] loss: 0.127723 metric: 0.909091 time: 1.4 s\n",
      "[1 100] loss: 0.125935 metric: 0.910891 time: 1.4 s\n",
      "[1 150] loss: 0.117511 metric: 0.948454 time: 1.4 s\n",
      "[1 200] loss: 0.119179 metric: 0.894118 time: 1.4 s\n",
      "[1 250] loss: 0.124890 metric: 0.883117 time: 1.4 s\n",
      "[1 300] loss: 0.124726 metric: 0.919540 time: 1.4 s\n",
      "Evaluating....\n",
      "**************************************************\n",
      "[epoch 1]. loss: 0.614114 acc: 0.773983 f1: 0.394246 time: 10.1 s\n",
      "**************************************************\n",
      "save model...\n",
      "learning rate: 0.000669\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-9795c820ce37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mbatch_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                     \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_every = 50\n",
    "best_state = None\n",
    "max_metric = 0\n",
    "def predict_on(model, data_dl, loss_func, device, model_state_path=None):\n",
    "#     if model_state_path:\n",
    "#         model.load_state_dict(torch.load(model_state_path))\n",
    "#         print('Start predicting...')\n",
    "    model.eval()\n",
    "    res_list = []\n",
    "    label_list = []\n",
    "    loss = 0\n",
    "    for text1, text2, label in data_dl:\n",
    "        text1 = pad_seq(text1, STR_MAXLEN)\n",
    "        text2 = pad_seq(text2, STR_MAXLEN)\n",
    "        y_pred = model(text1, text2)\n",
    "        loss += loss_func(y_pred, label).data.cpu()\n",
    "        y_pred = y_pred.data.max(1)[1].cpu().numpy()\n",
    "        res_list.extend(y_pred)\n",
    "        label_list.extend(label.data.cpu().numpy())\n",
    "    acc = accuracy_score(res_list, label_list)\n",
    "    Precision = precision_score(res_list, label_list)\n",
    "    Recall = recall_score(res_list, label_list)\n",
    "    F1 = f1_score(res_list, label_list)\n",
    "    return loss, (acc, Precision, Recall, F1)\n",
    "\n",
    "def evaluate(model, txt1, txt2, y):\n",
    "    pred = model(txt1, txt2)\n",
    "    F1 = f1_score(pred.data.max(1)[1].cpu(), y)\n",
    "    return F1\n",
    "\n",
    "def training_termination(valid_result):\n",
    "    if len(valid_result) >= 4:\n",
    "        if valid_result[-1] < valid_result[-2] and \\\n",
    "            valid_result[-2] < valid_result[-3] and \\\n",
    "            valid_result[-3] < valid_result[-4]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "print('start train...')\n",
    "valid_iter.create_batches()\n",
    "valid_batch_num = len(list(valid_iter.batches))\n",
    "train_iter.create_batches()\n",
    "batch_num = len(list(train_iter.batches))\n",
    "valid_result = []\n",
    "print('batch number ', batch_num)\n",
    "for epoch in range(EPOCHES):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('learning rate: %.6f'% param_group['lr'])\n",
    "    epoch_begin = time()\n",
    "    total_loss = 0.0\n",
    "    train_iter.init_epoch()\n",
    "    batch_count = 0\n",
    "    batch_begin_time = time()\n",
    "    for text1, text2, label in train_dl:\n",
    "        text1 = pad_seq(text1, STR_MAXLEN)\n",
    "        text2 = pad_seq(text2, STR_MAXLEN)\n",
    "        y_pred = model(text1, text2)\n",
    "#         print(text1)\n",
    "        loss = criterion(y_pred, label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        if batch_count % print_every == 0:\n",
    "            metric = evaluate(model.eval(), text1, text2, label)\n",
    "            print('[%d %d] loss: %.6f metric: %.6f time: %.1f s' %\n",
    "                  (epoch + 1, batch_count, total_loss / print_every, metric, time() - batch_begin_time))\n",
    "            total_loss = 0.0\n",
    "            batch_begin_time = time()\n",
    "    scheduler.step()\n",
    "    print(\"Evaluating....\")\n",
    "    loss, (acc, Precision, Recall, F1) = predict_on(model, valid_dl, criterion, DEVICE)\n",
    "    valid_result.append(F1)\n",
    "    print_flush('*'*50)\n",
    "    print_flush('[epoch %d]. loss: %.6f acc: %.6f f1: %.6f time: %.1f s'%(epoch+1, loss/valid_batch_num, acc, F1, time()-epoch_begin))\n",
    "    print_flush('*'*50)\n",
    "    if F1 > max_metric:\n",
    "        best_state = model.state_dict()\n",
    "        max_metric = F1\n",
    "        print_flush(\"save model...\")\n",
    "#         torch.save(best_state, './datasets/baseline_LSTM.pth')\n",
    "    epoch_begin = time()\n",
    "    if training_termination(valid_result):\n",
    "        print_flush(\"early stop at [%d] epoch!\" % (epoch+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?nn.AvgPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.1606, -1.2174,  0.3667,  1.2651,  1.2977],\n",
       "          [ 0.4916, -0.0915, -0.3557,  1.4138, -1.3672],\n",
       "          [ 1.2788, -2.1588,  1.0595,  1.6671, -0.6631]]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 1, 3, 5)\n",
    "avg = nn.AvgPool2d((3, 1), stride=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3103, -1.1559,  0.3569,  1.4487, -0.2442]]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = avg(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
