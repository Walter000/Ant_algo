{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、原始最高50左右，结合ESIM后57，加入pretrain的embedding效果变差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x193ff3ca390>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import jieba\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchtext import data\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# hyper parameters\n",
    "STR_MAXLEN = 30\n",
    "BATCH_SIZE = 256\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EMBED_DIM = 300\n",
    "HIDDEN_DIM = 150\n",
    "DEEP_LAYERS = [300]\n",
    "LEARNING_RATE = 1e-3*0.95\n",
    "EPOCHES = 20\n",
    "DECAY_STEP = 2\n",
    "DECAY_GAMMA = 0.99\n",
    "CLASS_WEIGHT = [0.6116, 2.7397]\n",
    "def print_flush(data, args=None):\n",
    "    if args == None:\n",
    "        print(data)\n",
    "    else:\n",
    "        print(data, args)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def pad_seq(seq, max_length):\n",
    "    length = len(seq[0])\n",
    "    pad_leng = 0 if length > max_length else (max_length-length)\n",
    "    if pad_leng == 0:\n",
    "        seq = seq[:, :max_length]\n",
    "    else:\n",
    "        seq = torch.cat([seq, torch.ones(len(seq), pad_leng).long().to(DEVICE)], dim=1)\n",
    "    return seq\n",
    "\n",
    "def Frobenius(mat):\n",
    "    size = mat.size()\n",
    "    if len(size) == 3:  # batched matrix\n",
    "        ret = (torch.sum(torch.sum((mat ** 2), 2), 1).squeeze() + 1e-10) ** 0.5\n",
    "        return torch.sum(ret) / size[0]\n",
    "    else:\n",
    "        raise Exception('matrix for computing Frobenius norm should be with 3 dims')\n",
    "\n",
    "def get_mask(txt1, txt2):\n",
    "    txt1 = txt1.cpu().numpy()\n",
    "    txt2 = txt2.cpu().numpy()\n",
    "    len_txt1 = len(txt1[0])\n",
    "    len_txt2 = len(txt2[0])\n",
    "    mask_txt1 = np.zeros(shape=[len(txt1), len_txt1])\n",
    "    mask_txt2 = np.zeros(shape=[len(txt2), len_txt2])\n",
    "    for i in range(len(txt1)):\n",
    "        mask_len1 = np.where(txt1[i] == 1)[0]\n",
    "        mask_len2 = np.where(txt2[i] == 1)[0]\n",
    "        if len(mask_len1) == 0:\n",
    "            mask_txt1[i, :] = 1\n",
    "        else:\n",
    "            mask_txt1[i, :mask_len1[0]] = 1\n",
    "        if len(mask_len2) == 0:\n",
    "            mask_txt2[i, :] = 1\n",
    "        else:\n",
    "            mask_txt2[i, :mask_len2[0]] = 1\n",
    "    return torch.tensor(mask_txt1).float().to(DEVICE), torch.tensor(mask_txt2).float().to(DEVICE)       \n",
    "\n",
    "def wordmodel_to_matrix(pretrain_path, wordlist, device, dim=300):\n",
    "    word_vec = gensim.models.Word2Vec.load(pretrain_path).wv\n",
    "    word_vec_list = []\n",
    "    oov = 0\n",
    "    oov_words = []\n",
    "    for idx, word in enumerate(wordlist):\n",
    "        try:\n",
    "            vector = np.array(word_vec[word], dtype=float).reshape(1,dim)\n",
    "        except:\n",
    "            oov += 1\n",
    "            oov_words.append(word)\n",
    "            # print(word)\n",
    "            vector = np.random.rand(1, dim)\n",
    "        word_vec_list.append(torch.from_numpy(vector))\n",
    "    wordvec_matrix = torch.cat(word_vec_list)\n",
    "    print(\"Load embedding finished.\")\n",
    "    print(\"Total words count: {}, oov count: {}.\".format(wordvec_matrix.size()[0], oov))\n",
    "    return wordvec_matrix if device == -1 else wordvec_matrix.to(device)\n",
    "\n",
    "def wordlist_to_matrix(pretrain_path, wordlist, device, dim=300):\n",
    "    word_vec = {}\n",
    "    with open(pretrain_path, encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            line = line.split(' ')\n",
    "            word = line[0]\n",
    "            vec = line[1:]\n",
    "            word_vec[word] = np.array(vec, dtype=float)\n",
    "    word_vec_list = []\n",
    "    oov = 0\n",
    "    oov_words = []\n",
    "    for idx, word in enumerate(wordlist):\n",
    "        try:\n",
    "            vector = np.array(word_vec[word], dtype=float).reshape(1,dim)\n",
    "        except:\n",
    "            oov += 1\n",
    "            oov_words.append(word)\n",
    "            # print(word)\n",
    "            vector = np.random.rand(1, dim)\n",
    "        word_vec_list.append(torch.from_numpy(vector))\n",
    "    wordvec_matrix = torch.cat(word_vec_list)\n",
    "    print(\"Load embedding finished.\")\n",
    "    print(\"Total words count: {}, oov count: {}.\".format(wordvec_matrix.size()[0], oov))\n",
    "    return wordvec_matrix if device == -1 else wordvec_matrix.to(device)\n",
    "\n",
    "torch.manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process raw data...\n",
      "Building vocabulary Finished.\n",
      "Load embedding finished.\n",
      "Total words count: 1517, oov count: 216.\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [txt for txt in text]\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, iter_columns):\n",
    "        self.dl, self.iter_columns = dl, iter_columns  # we pass in the list of attributes for x &amp;amp;amp;amp;lt;g class=\"gr_ gr_3178 gr-alert gr_spell gr_inline_cards gr_disable_anim_appear ContextualSpelling ins-del\" id=\"3178\" data-gr-id=\"3178\"&amp;amp;amp;amp;gt;and y&amp;amp;amp;amp;lt;/g&amp;amp;amp;amp;gt;\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield (getattr(batch, attr) for attr in self.iter_columns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "print_flush('process raw data...')\n",
    "TEXT = data.Field(sequential=True, use_vocab=True, eos_token='<EOS>', init_token='<BOS>',pad_token='<PAD>', \n",
    "                  batch_first=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "tv_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"txt1\", TEXT), (\"txt2\", TEXT),\n",
    "                 (\"label\", LABEL)]\n",
    "\n",
    "train = data.TabularDataset(path='../datasets/train_random.csv', format='csv', skip_header=True, fields=tv_datafields)\n",
    "valid = data.TabularDataset(path='../datasets/valid_random.csv', format='csv', skip_header=True, fields=tv_datafields)\n",
    "\n",
    "TEXT.build_vocab(train, valid, min_freq=3)\n",
    "print_flush('Building vocabulary Finished.')\n",
    "\n",
    "matrix = wordmodel_to_matrix('../datasets/pretrain_embedding/raw_embedding_300d.bin', TEXT.vocab.itos, DEVICE)\n",
    "\n",
    "train_iter = data.BucketIterator(dataset=train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.txt1) + len(x.txt2), shuffle=True, device=-1, repeat=False)\n",
    "valid_iter = data.Iterator(dataset=valid, batch_size=BATCH_SIZE, device=-1, shuffle=False, repeat=False)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, [\"txt1\", \"txt2\", \"label\"])\n",
    "valid_dl = BatchWrapper(valid_iter, [\"txt1\", \"txt2\", \"label\"])\n",
    "\n",
    "print_flush('prepare data done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hybrid_cnn_rnn(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim, hidden_dim, deep_layers, pretrain_embed=torch.tensor([]), is_batch_norm=False, is_drop_out=False):\n",
    "        super(Hybrid_cnn_rnn, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.deep_layers = deep_layers\n",
    "        self.is_batch_norm = is_batch_norm\n",
    "        self.is_drop_out = is_drop_out\n",
    "        self.word_embed = nn.Embedding(len(vocab), embed_dim, padding_idx=vocab['<PAD>'])\n",
    "        if len(pretrain_embed) != 0:\n",
    "            self.word_embed.weight.data.copy_(pretrain_embed)\n",
    "        self.lstm_embed = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.cnn_extract = nn.Conv2d(1, 5, (hidden_dim*2, 1))\n",
    "        self.linear_1 = nn.Linear(hidden_dim*2, deep_layers[0])\n",
    "        if self.is_batch_norm:\n",
    "            self.batch_norm_1 = nn.BatchNorm1d(deep_layers[0])\n",
    "        if self.is_drop_out:\n",
    "            self.linear_1_dropout = nn.Dropout(0.8)\n",
    "        for i, h in enumerate(self.deep_layers[1:], 1):\n",
    "            setattr(self,'linear_'+str(i+1), nn.Linear(self.deep_layers[i-1], self.deep_layers[i]))\n",
    "            if self.is_batch_norm:\n",
    "                setattr(self, 'batch_norm_' + str(i + 1), nn.BatchNorm1d(deep_layers[i]))\n",
    "            if self.is_drop_out:\n",
    "                setattr(self, 'linear_'+str(i+1)+'_dropout', nn.Dropout(0.8))\n",
    "#         self.attention_feature_layer = nn.Linear(STR_MAXLEN, hidden_dim*2)\n",
    "        self.lstm_fusion = nn.LSTM(2*hidden_dim*4+5, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.linear_1 = nn.Linear(2*hidden_dim*2, deep_layers[0])\n",
    "        self.deep_out = nn.Linear(deep_layers[-1], 2)\n",
    "#         self.deep_dropout_1 = nn.Dropout(0.5)\n",
    "    def forward(self, txt1, txt2, x1_mask, x2_mask, hidden=None):\n",
    "        embed_txt1 = self.word_embed(txt1)\n",
    "        embed_txt2 = self.word_embed(txt2)\n",
    "        lstm_txt1 = self.lstm_embed(embed_txt1, None)[0]\n",
    "        lstm_txt2 = self.lstm_embed(embed_txt2, None)[0]\n",
    "        lstm_txt1 = lstm_txt1 * x1_mask[:, :, None]\n",
    "        lstm_txt2 = lstm_txt2 * x2_mask[:, :, None]\n",
    "        lstm_txt1_ = lstm_txt1.transpose(2, 1).unsqueeze(1)\n",
    "        lstm_txt2_ = lstm_txt2.transpose(2, 1).unsqueeze(1)\n",
    "        cnn_encode1 = F.relu(self.cnn_extract(lstm_txt1_)).squeeze().transpose(1, 2)\n",
    "        cnn_encode2 = F.relu(self.cnn_extract(lstm_txt2_)).squeeze().transpose(1, 2)\n",
    "        \n",
    "#         cnn_encode1 = F.max_pool2d(cnn_encode1, (len(txt1[0]), 1)).squeeze()\n",
    "#         cnn_encode2 = F.max_pool2d(cnn_encode2, (len(txt2[0]), 1)).squeeze()\n",
    "        \n",
    "        weight_matrix = torch.bmm(lstm_txt1, lstm_txt2.permute(0, 2, 1))\n",
    "        weight_matrix_1 = torch.exp(weight_matrix - weight_matrix.max(2, keepdim=True)[0])\n",
    "        weight_matrix_2 = torch.exp(weight_matrix - weight_matrix.max(1, keepdim=True)[0])\n",
    "    \n",
    "        alphas = weight_matrix_1 / weight_matrix_1.sum(2, keepdim=True)\n",
    "        beta = weight_matrix_2 / weight_matrix_2.sum(1, keepdim=True)\n",
    "        alphas = alphas * x1_mask[:, :, None]\n",
    "        beta = beta * x2_mask[:, None, :]\n",
    "        \n",
    "        atten_txt1to2 = torch.bmm(alphas, lstm_txt2)\n",
    "        atten_txt2to1 = torch.bmm(beta.permute(0, 2, 1), lstm_txt1)\n",
    "        \n",
    "        txt_substract1 = torch.abs(lstm_txt1-atten_txt1to2)\n",
    "        txt_substract2 = torch.abs(lstm_txt2-atten_txt2to1)\n",
    "        \n",
    "        txt_multiply1 = torch.mul(lstm_txt1, atten_txt1to2)\n",
    "        txt_multiply2 = torch.mul(lstm_txt2, atten_txt2to1)\n",
    "        \n",
    "        out_txt1 = torch.cat([lstm_txt1, atten_txt1to2, txt_substract1, txt_multiply1, cnn_encode1], 2)\n",
    "        out_txt2 = torch.cat([lstm_txt2, atten_txt2to1, txt_substract2, txt_multiply2, cnn_encode2], 2)\n",
    "        lstm_fusion_txt1 = self.lstm_fusion(out_txt1, None)[0]\n",
    "        lstm_fusion_txt2 = self.lstm_fusion(out_txt2, None)[0]\n",
    "        lstm_fusion_txt1 = lstm_fusion_txt1.unsqueeze(1)\n",
    "        lstm_fusion_txt2 = lstm_fusion_txt2.unsqueeze(1)\n",
    "        lstm_txt1_max = F.max_pool2d(lstm_fusion_txt1, (len(txt1[0]), 1)).squeeze()\n",
    "        lstm_txt2_max = F.max_pool2d(lstm_fusion_txt2, (len(txt2[0]), 1)).squeeze() \n",
    "        output = self.linear_1(torch.cat([lstm_txt1_max, lstm_txt2_max], 1))\n",
    "        if self.is_batch_norm:\n",
    "            output = self.batch_norm_1(output)\n",
    "        output = F.relu(output)\n",
    "        if self.is_drop_out:\n",
    "            output = self.linear_1_dropout(output)\n",
    "        for i in range(1, len(self.deep_layers)):\n",
    "            output = getattr(self, 'linear_' + str(i + 1))(output)\n",
    "            if self.is_batch_norm:\n",
    "                output = getattr(self, 'batch_norm_' + str(i + 1))(output)\n",
    "            output = F.relu(output)\n",
    "            if self.is_drop_out:\n",
    "                output = getattr(self, 'linear_' + str(i + 1) + '_dropout')(output)\n",
    "        output = self.deep_out(output)\n",
    "        return F.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hybrid_rnn_cnn_V2(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim, hidden_dim, deep_layers, pretrain_embed=torch.tensor([])):\n",
    "        super(Hybrid_rnn_cnn_V2, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.deep_layers = deep_layers\n",
    "        self.word_embed = nn.Embedding(len(vocab), embed_dim, padding_idx=vocab.stoi['<PAD>'])\n",
    "        if len(pretrain_embed) != 0:\n",
    "            self.word_embed.weight.data.copy_(pretrain_embed)\n",
    "        self.lstm_embed = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.conv_step2 = nn.Conv2d(1, 40, (hidden_dim*2, 2))\n",
    "        self.conv_step3 = nn.Conv2d(1, 40, (hidden_dim*2, 3))\n",
    "        self.conv_step4 = nn.Conv2d(1, 40, (hidden_dim*2, 4))\n",
    "        self.lstm_fusion = nn.LSTM(2 * hidden_dim * 4, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.deep_layer_1 = nn.Linear(4*hidden_dim, deep_layers[0])\n",
    "        self.deep_out = nn.Linear(deep_layers[0], 2)\n",
    "#         self.deep_dropout_1 = nn.Dropout(0.5)\n",
    "    def forward(self, txt1, txt2, hidden=None):\n",
    "        embed_txt1 = self.word_embed(txt1)\n",
    "        embed_txt2 = self.word_embed(txt2)\n",
    "        lstm_txt1 = self.lstm_embed(embed_txt1, None)[0]\n",
    "        lstm_txt2 = self.lstm_embed(embed_txt2, None)[0]\n",
    "        \n",
    "        lstm_txt1_ = lstm_txt1.transpose(2, 1).unsqueeze(1)\n",
    "        lstm_txt2_ = lstm_txt2.transpose(2, 1).unsqueeze(1)\n",
    "        lstm_txt1_step2 = F.relu(self.conv_step2(lstm_txt1_)).permute(0, 2, 3, 1)\n",
    "        lstm_txt2_step2 = F.relu(self.conv_step2(lstm_txt2_)).permute(0, 2, 3, 1)\n",
    "        lstm_txt1_step3 = F.relu(self.conv_step3(lstm_txt1_)).permute(0, 2, 3, 1)\n",
    "        lstm_txt2_step3 = F.relu(self.conv_step3(lstm_txt2_)).permute(0, 2, 3, 1)\n",
    "        lstm_txt1_step4 = F.relu(self.conv_step4(lstm_txt1_)).permute(0, 2, 3, 1)\n",
    "        lstm_txt2_step4 = F.relu(self.conv_step4(lstm_txt2_)).permute(0, 2, 3, 1)\n",
    "        \n",
    "        \n",
    "        lstm_txt1_step2 = F.max_pool2d(lstm_txt1_step2, (lstm_txt1_step2.size(2), 1)).squeeze()\n",
    "        lstm_txt2_step2 = F.max_pool2d(lstm_txt2_step2, (lstm_txt2_step2.size(2), 1)).squeeze()\n",
    "        lstm_txt1_step3 = F.max_pool2d(lstm_txt1_step3, (lstm_txt1_step3.size(2), 1)).squeeze()\n",
    "        lstm_txt2_step3 = F.max_pool2d(lstm_txt2_step3, (lstm_txt2_step3.size(2), 1)).squeeze()\n",
    "        lstm_txt1_step4 = F.max_pool2d(lstm_txt1_step4, (lstm_txt1_step4.size(2), 1)).squeeze()\n",
    "        lstm_txt2_step4 = F.max_pool2d(lstm_txt2_step4, (lstm_txt2_step4.size(2), 1)).squeeze()\n",
    "        \n",
    "#         convout_txt1 = torch.cat([lstm_txt1_step2, lstm_txt1_step3, lstm_txt1_step4], 1)\n",
    "#         convout_txt2 = torch.cat([lstm_txt2_step2, lstm_txt2_step3, lstm_txt2_step4], 1)\n",
    "        \n",
    "        txt_substract_step2 = torch.abs(lstm_txt1_step2 - lstm_txt2_step2)\n",
    "        txt_multiply_step2 = torch.mul(lstm_txt1_step2, lstm_txt2_step2)\n",
    "        txt_substract_step3 = torch.abs(lstm_txt1_step3 - lstm_txt2_step3)\n",
    "        txt_multiply_step3 = torch.mul(lstm_txt1_step3, lstm_txt2_step3)\n",
    "        txt_substract_step4 = torch.abs(lstm_txt1_step4 - lstm_txt2_step4)\n",
    "        txt_multiply_step4 = torch.mul(lstm_txt1_step4, lstm_txt2_step4)\n",
    "    \n",
    "        lstm_txt1 = lstm_txt1.unsqueeze(1)\n",
    "        lstm_txt2 = lstm_txt2.unsqueeze(1)\n",
    "        lstm_txt1 = F.max_pool2d(lstm_txt1, (len(txt1[0]), 1)) \n",
    "        lstm_txt2 = F.max_pool2d(lstm_txt2, (len(txt2[0]), 1))\n",
    "        lstm_txt1 = lstm_txt1.squeeze()\n",
    "        lstm_txt2 = lstm_txt2.squeeze()\n",
    "        txt_substract = torch.abs(lstm_txt1 - lstm_txt2)\n",
    "        txt_multiply = torch.mul(lstm_txt1, lstm_txt2)\n",
    "        output = F.relu(self.deep_layer_1(torch.cat([\n",
    "                                                     txt_substract, txt_multiply], 1)))\n",
    "        output = self.deep_out(output)\n",
    "        return F.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Hybrid_rnn_cnn_V2(TEXT.vocab, EMBED_DIM, HIDDEN_DIM, DEEP_LAYERS, matrix)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.NLLLoss(weight=torch.tensor(CLASS_WEIGHT).float().to(DEVICE))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = StepLR(optimizer, step_size=DECAY_STEP, gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "batch number 325 \n",
      "learning rate: 0.000950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 50] loss: 0.605378 metric: 0.481481 time: 1.9 s\n",
      "[1 100] loss: 0.582363 metric: 0.546875 time: 1.8 s\n",
      "[1 150] loss: 0.534018 metric: 0.635135 time: 1.9 s\n",
      "[1 200] loss: 0.520522 metric: 0.452555 time: 1.8 s\n",
      "[1 250] loss: 0.530053 metric: 0.544218 time: 1.9 s\n",
      "[1 300] loss: 0.507771 metric: 0.594203 time: 1.8 s\n",
      "Evaluating....\n",
      "************************************************************\n",
      "[epoch 1]. loss: 0.494535 acc: 0.750809 f1: 0.527280 time: 13.6 s\n",
      "************************************************************\n",
      "save model...\n",
      "learning rate: 0.000950\n",
      "[2 50] loss: 0.459220 metric: 0.569697 time: 2.1 s\n",
      "[2 100] loss: 0.463340 metric: 0.532258 time: 1.8 s\n",
      "[2 150] loss: 0.471475 metric: 0.625000 time: 1.9 s\n",
      "[2 200] loss: 0.476645 metric: 0.647059 time: 1.8 s\n",
      "[2 250] loss: 0.461979 metric: 0.589928 time: 2.0 s\n",
      "[2 300] loss: 0.463386 metric: 0.607407 time: 1.9 s\n",
      "Evaluating....\n",
      "************************************************************\n",
      "[epoch 2]. loss: 0.488344 acc: 0.792050 f1: 0.555592 time: 13.7 s\n",
      "************************************************************\n",
      "save model...\n",
      "learning rate: 0.000950\n",
      "[3 50] loss: 0.406174 metric: 0.602941 time: 1.9 s\n",
      "[3 100] loss: 0.415961 metric: 0.578947 time: 1.7 s\n",
      "[3 150] loss: 0.421887 metric: 0.662069 time: 1.7 s\n",
      "[3 200] loss: 0.435012 metric: 0.560510 time: 1.8 s\n",
      "[3 250] loss: 0.432891 metric: 0.633803 time: 1.8 s\n",
      "[3 300] loss: 0.433694 metric: 0.585366 time: 1.8 s\n",
      "Evaluating....\n",
      "************************************************************\n",
      "[epoch 3]. loss: 0.484641 acc: 0.755226 f1: 0.535659 time: 13.2 s\n",
      "************************************************************\n",
      "learning rate: 0.000950\n",
      "[4 50] loss: 0.353174 metric: 0.705036 time: 1.9 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-31402dcbf27c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mbatch_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                     \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_every = 50\n",
    "best_state = None\n",
    "max_metric = 0\n",
    "# model.to(DEVICE)\n",
    "def predict(model, data_dl, loss_func, device):\n",
    "    model.eval()\n",
    "    res_list = []\n",
    "    label_list = []\n",
    "    loss = 0\n",
    "    for text1, text2, label in data_dl:\n",
    "        text1 = text1.to(DEVICE)\n",
    "        text2 = text2.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "#         x1_mask, x2_mask = get_mask(text1, text2)\n",
    "        y_pred = model(text1, text2)\n",
    "        loss += loss_func(y_pred, label).data.cpu()\n",
    "        y_pred = y_pred.data.max(1)[1].cpu().numpy()\n",
    "        res_list.extend(y_pred)\n",
    "        label_list.extend(label.data.cpu().numpy())\n",
    "    acc = accuracy_score(res_list, label_list)\n",
    "    Precision = precision_score(res_list, label_list)\n",
    "    Recall = recall_score(res_list, label_list)\n",
    "    F1 = f1_score(res_list, label_list)\n",
    "    \n",
    "    return loss, (acc, Precision, Recall, F1)\n",
    "        \n",
    "def evaluate(model, txt1, txt2, y):\n",
    "    pred = model(txt1, txt2)\n",
    "    out_batch = pred.data.max(1)[1].cpu().numpy()\n",
    "    F1 = f1_score(out_batch, y)\n",
    "    return F1\n",
    "\n",
    "def training_termination(valid_result):\n",
    "    if len(valid_result) >= 4:\n",
    "        if valid_result[-1] < valid_result[-2] and \\\n",
    "            valid_result[-2] < valid_result[-3] and \\\n",
    "            valid_result[-3] < valid_result[-4]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "valid_iter.create_batches()\n",
    "valid_batch_num = len(list(valid_iter.batches))\n",
    "print_flush('start train...')\n",
    "train_iter.create_batches()\n",
    "batch_num = len(list(train_iter.batches))\n",
    "print_flush('batch number %d '%batch_num)\n",
    "valid_result = []\n",
    "for epoch in range(EPOCHES):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('learning rate: %.6f'% param_group['lr'])\n",
    "    epoch_begin = time()\n",
    "    total_loss = 0.0\n",
    "    train_iter.init_epoch()\n",
    "    batch_count = 0\n",
    "    batch_begin_time = time()\n",
    "    for text1, text2, label in train_dl:\n",
    "        model.train()\n",
    "        text1 = text1.to(DEVICE)\n",
    "        text2 = text2.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "#         x1_mask, x2_mask = get_mask(text1, text2)\n",
    "        y_pred = model(text1, text2)\n",
    "        loss = criterion(y_pred, label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        if batch_count % print_every == 0:\n",
    "            metric = evaluate(model.eval(), text1, text2, label)\n",
    "            print_flush('[%d %d] loss: %.6f metric: %.6f time: %.1f s' %\n",
    "                  (epoch + 1, batch_count, total_loss / print_every, metric, time() - batch_begin_time))\n",
    "            total_loss = 0.0\n",
    "            batch_begin_time = time()\n",
    "#     scheduler.step()\n",
    "    print_flush(\"Evaluating....\")\n",
    "    loss, (acc, Precision, Recall, F1) = predict(model, valid_dl, criterion, DEVICE)\n",
    "    valid_result.append(F1)\n",
    "    print_flush('*'*60)\n",
    "    print_flush('[epoch %d]. loss: %.6f acc: %.6f f1: %.6f time: %.1f s'%(epoch+1, loss/valid_batch_num, acc, F1, time()-epoch_begin))\n",
    "    print_flush('*'*60)\n",
    "    if F1 > max_metric:\n",
    "        best_state = model.state_dict()\n",
    "        max_metric = F1\n",
    "        print_flush(\"save model...\")\n",
    "        torch.save(best_state, '../datasets/models/baseline_LSTM.pth')\n",
    "    epoch_begin = time()\n",
    "    if training_termination(valid_result):\n",
    "        print_flush(\"early stop at [%d] epoch!\" % (epoch+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(5, 5, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(1, 2, 5)\n",
    "out = lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
