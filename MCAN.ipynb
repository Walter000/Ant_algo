{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、普通attention 560\n",
    "\n",
    "2、普通ESIM 569\n",
    "\n",
    "3、加入full pretrain的ESIM 5779  加大deep到450 5796  HIDDEN_DIM = 200 DEEP_LAYERS = [500] 5811\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import jieba\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchtext import data\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# hyper parameters\n",
    "STR_MAXLEN = 30\n",
    "BATCH_SIZE = 256\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EMBED_DIM = 300\n",
    "ATTEN_DIM = 200\n",
    "HIDDEN_DIM = 200\n",
    "DEEP_LAYERS = [400]\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHES = 20\n",
    "DECAY_STEP = 2\n",
    "DECAY_GAMMA = 0.99\n",
    "CLASS_WEIGHT = [0.6116, 2.7397]\n",
    "def print_flush(data, args=None):\n",
    "    if args == None:\n",
    "        print(data)\n",
    "    else:\n",
    "        print(data, args)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def get_mask(txt1, txt2):\n",
    "    txt1 = txt1.cpu().numpy()\n",
    "    txt2 = txt2.cpu().numpy()\n",
    "    len_txt1 = len(txt1[0])\n",
    "    len_txt2 = len(txt2[0])\n",
    "    mask_txt1 = np.zeros(shape=[len(txt1), len_txt1])\n",
    "    mask_txt2 = np.zeros(shape=[len(txt2), len_txt2])\n",
    "    for i in range(len(txt1)):\n",
    "        mask_len1 = np.where(txt1[i] == 1)[0]\n",
    "        mask_len2 = np.where(txt2[i] == 1)[0]\n",
    "        if len(mask_len1) == 0:\n",
    "            mask_txt1[i, :] = 1\n",
    "        else:\n",
    "            mask_txt1[i, :mask_len1[0]] = 1\n",
    "        if len(mask_len2) == 0:\n",
    "            mask_txt2[i, :] = 1\n",
    "        else:\n",
    "            mask_txt2[i, :mask_len2[0]] = 1\n",
    "    return torch.tensor(mask_txt1).float().to(DEVICE), torch.tensor(mask_txt2).float().to(DEVICE)\n",
    "\n",
    "def wordmodel_to_matrix(pretrain_path, wordlist, device, dim=300):\n",
    "    word_vec = Word2Vec.load(pretrain_path).wv\n",
    "    word_vec_list = []\n",
    "    oov = 0\n",
    "    oov_words = []\n",
    "    for idx, word in enumerate(wordlist):\n",
    "        try:\n",
    "            vector = np.array(word_vec[word], dtype=float).reshape(1,dim)\n",
    "        except:\n",
    "            oov += 1\n",
    "            oov_words.append(word)\n",
    "            # print(word)\n",
    "            vector = np.random.rand(1, dim)\n",
    "        word_vec_list.append(torch.from_numpy(vector))\n",
    "    wordvec_matrix = torch.cat(word_vec_list)\n",
    "    print(\"Load embedding finished.\")\n",
    "    print(\"Total words count: {}, oov count: {}.\".format(wordvec_matrix.size()[0], oov))\n",
    "    return wordvec_matrix if device == -1 else wordvec_matrix.to(device)\n",
    "\n",
    "def wordlist_to_matrix(pretrain_path, wordlist, device, dim=300):\n",
    "    word_vec = {}\n",
    "    with open(pretrain_path, encoding='utf-8') as fr:\n",
    "        for line in fr:\n",
    "            line = line.split(' ')\n",
    "            word = line[0]\n",
    "            vec = line[1:]\n",
    "            word_vec[word] = np.array(vec, dtype=float)\n",
    "    word_vec_list = []\n",
    "    oov = 0\n",
    "    oov_words = []\n",
    "    for idx, word in enumerate(wordlist):\n",
    "        try:\n",
    "            vector = np.array(word_vec[word], dtype=float).reshape(1,dim)\n",
    "        except:\n",
    "            oov += 1\n",
    "            oov_words.append(word)\n",
    "            # print(word)\n",
    "            vector = np.random.rand(1, dim)\n",
    "        word_vec_list.append(torch.from_numpy(vector))\n",
    "    wordvec_matrix = torch.cat(word_vec_list)\n",
    "    print(\"Load embedding finished.\")\n",
    "    print(\"Total words count: {}, oov count: {}.\".format(wordvec_matrix.size()[0], oov))\n",
    "    return wordvec_matrix if device == -1 else wordvec_matrix.to(device)\n",
    "\n",
    "# torch.manual_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process raw data...\n",
      "Building vocabulary Finished.\n",
      "Load embedding finished.\n",
      "Total words count: 1517, oov count: 216.\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [txt for txt in text]\n",
    "class BatchWrapper:\n",
    "    def __init__(self, dl, iter_columns):\n",
    "        self.dl, self.iter_columns = dl, iter_columns  # we pass in the list of attributes for x &amp;amp;amp;amp;lt;g class=\"gr_ gr_3178 gr-alert gr_spell gr_inline_cards gr_disable_anim_appear ContextualSpelling ins-del\" id=\"3178\" data-gr-id=\"3178\"&amp;amp;amp;amp;gt;and y&amp;amp;amp;amp;lt;/g&amp;amp;amp;amp;gt;\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield (getattr(batch, attr) for attr in self.iter_columns)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "print_flush('process raw data...')\n",
    "TEXT = data.Field(sequential=True, use_vocab=True, eos_token='<EOS>', init_token='<BOS>',pad_token='<PAD>', \n",
    "                  batch_first=True, tokenize=tokenizer)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "tv_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"txt1\", TEXT), (\"txt2\", TEXT),\n",
    "                 (\"label\", LABEL)]\n",
    "\n",
    "train = data.TabularDataset(path='../datasets/train.csv', format='csv', skip_header=True, fields=tv_datafields)\n",
    "valid = data.TabularDataset(path='../datasets/valid.csv', format='csv', skip_header=True, fields=tv_datafields)\n",
    "\n",
    "TEXT.build_vocab(train, valid, min_freq=3)\n",
    "print_flush('Building vocabulary Finished.')\n",
    "\n",
    "# matrix = wordlist_to_matrix('../datasets/pretrain_embedding/pretrain_full_emb.txt', TEXT.vocab.itos, DEVICE)\n",
    "matrix = wordmodel_to_matrix('../datasets/pretrain_embedding/raw_embedding_300d.bin', TEXT.vocab.itos, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1517"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare data done!\n"
     ]
    }
   ],
   "source": [
    "train_iter = data.BucketIterator(dataset=train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.txt1) + len(x.txt2), shuffle=False, device=-1, repeat=False)\n",
    "valid_iter = data.Iterator(dataset=valid, batch_size=BATCH_SIZE, device=-1, shuffle=False, repeat=False)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, [\"txt1\", \"txt2\", \"label\"])\n",
    "valid_dl = BatchWrapper(valid_iter, [\"txt1\", \"txt2\", \"label\"])\n",
    "\n",
    "print_flush('prepare data done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(x1, x2):\n",
    "    '''compute cosine similarity between x1 and x2\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, x2 : 2-D torch Tensor\n",
    "        size (batch_size, 1)\n",
    "    Returns\n",
    "    -------\n",
    "    distance : 2-D torch Tensor\n",
    "        similarity result of size (batch_size, 1)\n",
    "    '''\n",
    "    return F.cosine_similarity(x1, x2).unsqueeze(1)\n",
    "def attention_matrix(x1, x2, eps=1e-6):\n",
    "    '''compute attention matrix using match score\n",
    "    \n",
    "    1 / (1 + |x · y|)\n",
    "    |·| is euclidean distance\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, x2 : 4-D torch Tensor\n",
    "        size (batch_size, 1, sentence_length, h)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : 3-D torch Tensor\n",
    "        match score result of size (batch_size, sentence_length(for x2), sentence_length(for x1))\n",
    "    '''\n",
    "    eps = torch.tensor(eps).to(DEVICE)\n",
    "    one = torch.tensor(1.).to(DEVICE)\n",
    "    euclidean = (torch.pow(x1 - x2.permute(0, 2, 1, 3), 2).sum(dim=3) + eps).sqrt()\n",
    "    return (euclidean + one).reciprocal()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highway_network(highway_network_linear, data_in, num_layers, output_size = None):\n",
    "    def highway_layer(highway_network_linear, data_in, output_size = None):\n",
    "        size = data_in.size()\n",
    "        if len(size) > 2:\n",
    "            inputs = data_in.view(size[0]*size[1], size[2])\n",
    "        else:\n",
    "            inputs = data_in\n",
    "        if output_size is not None:\n",
    "            d = output_size\n",
    "        else:\n",
    "            d = data_in.size()[-1]\n",
    "        trans = highway_network_linear(inputs)\n",
    "        trans = F.relu(trans)\n",
    "        gate = highway_network_linear(inputs)\n",
    "        gate = F.sigmoid(gate)\n",
    "        if d != data_in.size()[-1]:\n",
    "            data_in = highway_network_linear(inputs)\n",
    "            out = gate * trans + (1 - gate) * inputs\n",
    "        else:\n",
    "            out = gate * trans + (1 - gate) * inputs\n",
    "        if len(size) > 2:\n",
    "            out = out.view(size[0], size[1], size[2])\n",
    "        return out\n",
    "\n",
    "    prev = data_in\n",
    "    for layer_idx in range(num_layers):\n",
    "        cur = highway_layer(highway_network_linear, prev, output_size = output_size)\n",
    "        prev = cur\n",
    "    return cur\n",
    "\n",
    "class CoAttention(nn.Module):\n",
    "    def __init__(self, input_dim, atten_dim):\n",
    "        super(CoAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.atten_dim = atten_dim\n",
    "        self.attention_align = nn.Linear(input_dim, atten_dim)\n",
    "        self.attention_max = nn.Linear(input_dim, atten_dim)\n",
    "        self.attention_mean = nn.Linear(input_dim, atten_dim)\n",
    "        self.attention_self = nn.Linear(input_dim, atten_dim)\n",
    "        self.compress_align = Compression(input_dim, 'nn')\n",
    "        self.compress_max = Compression(input_dim, 'nn')\n",
    "        self.compress_mean = Compression(input_dim, 'nn')\n",
    "        self.compress_self = Compression(input_dim, 'nn')\n",
    "        \n",
    "    def forward(self, lstm_txt1, lstm_txt2, x1_mask=None, x2_mask=None):\n",
    "        # alignment pooling\n",
    "        size1 = lstm_txt1.size()\n",
    "        size2 = lstm_txt2.size()\n",
    "        align_atten = torch.bmm(F.relu(self.attention_align(lstm_txt1.view(size1[0]*size1[1], size1[2]))).view(size1[0], size1[1], self.atten_dim),\n",
    "                        F.relu(self.attention_align(lstm_txt2.view(size2[0]*size2[1], size2[2]))).view(size2[0], size2[1], self.atten_dim).transpose(1, 2))\n",
    "        \n",
    "        alphas = F.softmax(align_atten, 2)\n",
    "        beta = F.softmax(align_atten, 1)\n",
    "#         alphas = alphas * x1_mask[:, :, None]\n",
    "#         beta = beta * x2_mask[:, None, :]\n",
    "        align_txt1 = torch.bmm(alphas, lstm_txt2)\n",
    "        align_txt2 = torch.bmm(beta.permute(0, 2, 1), lstm_txt1)\n",
    "        \n",
    "        fc_align_txt1 = torch.cat([align_txt1, lstm_txt1], 2)\n",
    "        fm_align_txt1 = align_txt1 * lstm_txt1\n",
    "        fs_align_txt1 = align_txt1 - lstm_txt1\n",
    "        fc_align_txt2 = torch.cat([align_txt2, lstm_txt2], 2)\n",
    "        fm_align_txt2 = align_txt2 * lstm_txt2\n",
    "        fs_align_txt2 = align_txt2 - lstm_txt2\n",
    "        \n",
    "        fc_align_txt1, fm_align_txt1, fs_align_txt1 = self.compress_align(fc_align_txt1, fm_align_txt1, fs_align_txt1)\n",
    "        fc_align_txt2, fm_align_txt2, fs_align_txt2 = self.compress_align(fc_align_txt2, fm_align_txt2, fs_align_txt2)\n",
    "        \n",
    "        # max pooling\n",
    "        max_atten = torch.bmm(F.relu(self.attention_max(lstm_txt1.view(size1[0]*size1[1], size1[2]))).view(size1[0], size1[1], self.atten_dim),\n",
    "                        F.relu(self.attention_max(lstm_txt2.view(size2[0]*size2[1], size2[2]))).view(size2[0], size2[1], self.atten_dim).transpose(1, 2))\n",
    "        max_row = F.softmax(torch.max(max_atten, 2, True)[0], dim=1)\n",
    "        max_row = max_row.repeat(1, 1, lstm_txt2.size(1))\n",
    "        max_txt1 = torch.bmm(max_row, lstm_txt2)\n",
    "        \n",
    "        max_col = torch.max(max_atten, 1, True)[0]\n",
    "        max_col = F.softmax(max_col, dim=2)\n",
    "        max_col = max_col.repeat(1, lstm_txt1.size(1), 1).transpose(1, 2)\n",
    "        max_txt2 = torch.bmm(max_col, lstm_txt1)\n",
    "        \n",
    "        fc_max_txt1 = torch.cat([max_txt1, lstm_txt1], 2)\n",
    "        fm_max_txt1 = max_txt1 * lstm_txt1\n",
    "        fs_max_txt1 = max_txt1 - lstm_txt1\n",
    "        fc_max_txt2 = torch.cat([max_txt2, lstm_txt2], 2)\n",
    "        fm_max_txt2 = max_txt2 * lstm_txt2\n",
    "        fs_max_txt2 = max_txt2 - lstm_txt2\n",
    "        \n",
    "        fc_max_txt1, fm_max_txt1, fs_max_txt1 = self.compress_max(fc_max_txt1, fm_max_txt1, fs_max_txt1)\n",
    "        fc_max_txt2, fm_max_txt2, fs_max_txt2 = self.compress_max(fc_max_txt2, fm_max_txt2, fs_max_txt2)\n",
    "        \n",
    "        # mean pooling\n",
    "        mean_atten = torch.bmm(F.relu(self.attention_mean(lstm_txt1.view(size1[0]*size1[1], size1[2]))).view(size1[0], size1[1], self.atten_dim),\n",
    "                        F.relu(self.attention_mean(lstm_txt2.view(size2[0]*size2[1], size2[2]))).view(size2[0], size2[1], self.atten_dim).transpose(1, 2))\n",
    "        mean_row = F.softmax(torch.mean(mean_atten, 2, True), dim=1)\n",
    "        mean_row = mean_row.repeat(1, 1, lstm_txt2.size(1))\n",
    "        mean_txt1 = torch.bmm(mean_row, lstm_txt2)\n",
    "        \n",
    "        mean_col = F.softmax(torch.mean(mean_atten, 1, True), dim=2)\n",
    "        mean_col = mean_col.repeat(1, lstm_txt1.size(1), 1).transpose(1, 2)\n",
    "        mean_txt2 = torch.bmm(mean_col, lstm_txt1)\n",
    "        \n",
    "        fc_mean_txt1 = torch.cat([mean_txt1, lstm_txt1], 2)\n",
    "        fm_mean_txt1 = mean_txt1 * lstm_txt1\n",
    "        fs_mean_txt1 = mean_txt1 - lstm_txt1\n",
    "        fc_mean_txt2 = torch.cat([mean_txt2, lstm_txt2], 2)\n",
    "        fm_mean_txt2 = mean_txt2 * lstm_txt2\n",
    "        fs_mean_txt2 = mean_txt2 - lstm_txt2\n",
    "        \n",
    "        fc_mean_txt1, fm_mean_txt1, fs_mean_txt1 = self.compress_mean(fc_mean_txt1, fm_mean_txt1, fs_mean_txt1)\n",
    "        fc_mean_txt2, fm_mean_txt2, fs_mean_txt2 = self.compress_mean(fc_mean_txt2, fm_mean_txt2, fs_mean_txt2)\n",
    "        \n",
    "        # self attention\n",
    "        self_atten1 = torch.bmm(F.relu(self.attention_self(lstm_txt1.view(size1[0]*size1[1], size1[2]))).view(size1[0], size1[1], self.atten_dim),\n",
    "                        F.relu(self.attention_self(lstm_txt1.view(size1[0]*size1[1], size1[2]))).view(size1[0], size1[1], self.atten_dim).transpose(1, 2))\n",
    "        self_atten2 = torch.bmm(F.relu(self.attention_self(lstm_txt2.view(size2[0]*size2[1], size2[2]))).view(size2[0], size2[1], self.atten_dim),\n",
    "                        F.relu(self.attention_self(lstm_txt2.view(size2[0]*size2[1], size2[2]))).view(size2[0], size2[1], self.atten_dim).transpose(1, 2))\n",
    "        self_atten1 = F.softmax(self_atten1, dim=2)\n",
    "        self_atten1 = torch.bmm(self_atten1, lstm_txt1)\n",
    "        \n",
    "        self_atten2 = F.softmax(self_atten2, dim=2)\n",
    "        self_atten2 = torch.bmm(self_atten2, lstm_txt2)\n",
    "        \n",
    "        fc_self_txt1 = torch.cat([self_atten1, lstm_txt1], 2)\n",
    "        fm_self_txt1 = self_atten1 * lstm_txt1\n",
    "        fs_self_txt1 = self_atten1 - lstm_txt1\n",
    "        fc_self_txt2 = torch.cat([self_atten2, lstm_txt2], 2)\n",
    "        fm_self_txt2 = self_atten2 * lstm_txt2\n",
    "        fs_self_txt2 = self_atten2 - lstm_txt2\n",
    "        \n",
    "        fc_self_txt1, fm_self_txt1, fs_self_txt1 = self.compress_self(fc_self_txt1, fm_self_txt1, fs_self_txt1)\n",
    "        fc_self_txt2, fm_self_txt2, fs_self_txt2 = self.compress_self(fc_self_txt2, fm_self_txt2, fs_self_txt2)\n",
    "        \n",
    "        return torch.cat([fc_align_txt1, fm_align_txt1, fs_align_txt1, fc_max_txt1, fm_max_txt1, fs_max_txt1,\n",
    "                         fc_mean_txt1, fm_mean_txt1, fs_mean_txt1,fc_self_txt1, fm_self_txt1, fs_self_txt1], 2), torch.cat([fc_align_txt2, fm_align_txt2, fs_align_txt2, fc_max_txt2, fm_max_txt2, fs_max_txt2,\n",
    "                         fc_mean_txt2, fm_mean_txt2, fs_mean_txt2, fc_self_txt2, fm_self_txt2, fs_self_txt2], 2)\n",
    "                \n",
    "                \n",
    "        \n",
    "class Compression(nn.Module):\n",
    "    def __init__(self, input_dim, choice):\n",
    "        super(Compression, self).__init__()\n",
    "        self.choice = choice\n",
    "        if choice == 'nn':\n",
    "            self.linear_concat = nn.Linear(2*input_dim, 1)\n",
    "            self.linear_mul = nn.Linear(input_dim, 1)\n",
    "            self.linear_sub = nn.Linear(input_dim, 1)\n",
    "        elif choice == 'fm':\n",
    "            pass\n",
    "        \n",
    "    def forward(self, concat, mul, sub):\n",
    "        size = mul.size()\n",
    "        if self.choice == 'nn':\n",
    "            out_concat = F.relu(self.linear_concat(concat.view(concat.size(0)*concat.size(1), concat.size(2))))\n",
    "            out_mul =  F.relu(self.linear_mul(mul.view(mul.size(0)*mul.size(1), mul.size(2))))\n",
    "            out_sub =  F.relu(self.linear_sub(sub.view(sub.size(0)*sub.size(1), sub.size(2))))\n",
    "            return out_concat.view(size[0], size[1], 1), out_mul.view(size[0], size[1], 1), out_sub.view(size[0], size[1], 1)\n",
    "        elif choice == 'sum':\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MCAN(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim, atten_dim, hidden_dim, deep_layers, pretrain_embed=torch.tensor([]), is_batch_norm=False, is_drop_out=False):\n",
    "        super(MCAN, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.atten_dim = atten_dim\n",
    "        self.deep_layers = deep_layers\n",
    "        self.is_batch_norm = is_batch_norm\n",
    "        self.is_drop_out = is_drop_out\n",
    "        self.word_embed = nn.Embedding(len(vocab), embed_dim, padding_idx=vocab['<PAD>'])\n",
    "        self.highway_layer = nn.Linear(embed_dim, embed_dim)\n",
    "        self.highway_layer2 = nn.Linear(4 * hidden_dim * 4, 4 * hidden_dim * 4)\n",
    "        self.attention_embed = CoAttention(embed_dim, atten_dim)\n",
    "        if len(pretrain_embed) != 0:\n",
    "            self.word_embed.weight.data.copy_(pretrain_embed)\n",
    "#             self.word_embed.weight.requires_grad = False\n",
    "        \n",
    "        # lstm encode operator\n",
    "        self.lstm_embed = nn.LSTM(embed_dim+12, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # MLP layer\n",
    "        self.linear_1 = nn.Linear(4 * hidden_dim * 4, deep_layers[0])\n",
    "        if self.is_batch_norm:\n",
    "            self.batch_norm_1 = nn.BatchNorm1d(deep_layers[0])\n",
    "        if self.is_drop_out:\n",
    "            self.linear_1_dropout = nn.Dropout(0.8)\n",
    "        for i, h in enumerate(self.deep_layers[1:], 1):\n",
    "            setattr(self,'linear_'+str(i+1), nn.Linear(self.deep_layers[i-1], self.deep_layers[i]))\n",
    "            if self.is_batch_norm:\n",
    "                setattr(self, 'batch_norm_' + str(i + 1), nn.BatchNorm1d(deep_layers[i]))\n",
    "            if self.is_drop_out:\n",
    "                setattr(self, 'linear_'+str(i+1)+'_dropout', nn.Dropout(0.8))\n",
    "        self.deep_out = nn.Linear(deep_layers[-1], 2)\n",
    "#         self.attention_feature_layer = nn.Linear(STR_MAXLEN, hidden_dim*2)\n",
    "        self.lstm_fusion = nn.LSTM(2 * hidden_dim * 4, hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, txt1, txt2, x1_mask, x2_mask, hidden=None):\n",
    "        embed_txt1 = self.word_embed(txt1)\n",
    "        embed_txt2 = self.word_embed(txt2)\n",
    "        embed_txt1 = highway_network(self.highway_layer, embed_txt1, 1)\n",
    "        embed_txt2 = highway_network(self.highway_layer, embed_txt2, 1)\n",
    "        new_fea_txt1, new_fea_txt2 = self.attention_embed(embed_txt1, embed_txt2)\n",
    "        embed_txt1 = torch.cat([embed_txt1, new_fea_txt1], 2)\n",
    "        embed_txt2 = torch.cat([embed_txt2, new_fea_txt2], 2)\n",
    "        lstm_txt1 = self.lstm_embed(embed_txt1, None)[0]\n",
    "        lstm_txt2 = self.lstm_embed(embed_txt2, None)[0]\n",
    "        lstm_txt1 = lstm_txt1 * x1_mask[:, :, None]\n",
    "        lstm_txt2 = lstm_txt2 * x2_mask[:, :, None]\n",
    "        lstm_txt1 = lstm_txt1.unsqueeze(1)\n",
    "        lstm_txt2 = lstm_txt2.unsqueeze(1)\n",
    "        \n",
    "        lstm_txt1_max = F.max_pool2d(lstm_txt1, (len(txt1[0]), 1)).squeeze()\n",
    "        lstm_txt2_max = F.max_pool2d(lstm_txt2, (len(txt2[0]), 1)).squeeze()\n",
    "#         txt_substract = torch.abs(lstm_txt1 - lstm_txt2)\n",
    "#         txt_multiply = torch.mul(lstm_txt1, lstm_txt2)\n",
    "#         output = self.deep_layer_1(torch.cat([lstm_txt1, lstm_txt2, txt_substract, txt_multiply], 1))\n",
    "        lstm_txt1_mean = F.avg_pool2d(lstm_txt1, (len(txt1[0]), 1)).squeeze()\n",
    "        lstm_txt2_mean = F.avg_pool2d(lstm_txt2, (len(txt2[0]), 1)).squeeze() \n",
    "        \n",
    "        final_txt1 = torch.cat([lstm_txt1_max, lstm_txt1_mean], 1)\n",
    "        final_txt2 = torch.cat([lstm_txt2_max, lstm_txt2_mean], 1)\n",
    "        txt_substract = torch.abs(final_txt1 - final_txt2)\n",
    "        txt_multiply = torch.mul(final_txt1, final_txt2)\n",
    "#         lstm_txt1_max = F.max_pool2d(lstm_fusion_txt1, (len(txt1[0]), 1)).squeeze()\n",
    "#         lstm_txt2_max = F.max_pool2d(lstm_fusion_txt2, (len(txt2[0]), 1)).squeeze() \n",
    "        output = highway_network(self.highway_layer2, torch.cat([final_txt1, final_txt2, txt_substract, txt_multiply], 1), 1)\n",
    "        output = self.linear_1(output)\n",
    "        if self.is_batch_norm:\n",
    "            output = self.batch_norm_1(output)\n",
    "        output = F.relu(output)\n",
    "        if self.is_drop_out:\n",
    "            output = self.linear_1_dropout(output)\n",
    "        for i in range(1, len(self.deep_layers)):\n",
    "            output = getattr(self, 'linear_' + str(i + 1))(output)\n",
    "            if self.is_batch_norm:\n",
    "                output = getattr(self, 'batch_norm_' + str(i + 1))(output)\n",
    "            output = F.relu(output)\n",
    "            if self.is_drop_out:\n",
    "                output = getattr(self, 'linear_' + str(i + 1) + '_dropout')(output)\n",
    "        output = self.deep_out(output)\n",
    "        return F.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MCAN(TEXT.vocab.stoi, EMBED_DIM, ATTEN_DIM, HIDDEN_DIM, DEEP_LAYERS, matrix)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.NLLLoss(weight=torch.tensor(CLASS_WEIGHT).float().to(DEVICE))\n",
    "# parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = StepLR(optimizer, step_size=DECAY_STEP, gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "batch number 337 \n",
      "learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 50] loss: 0.664888 metric: 0.426471 time: 6.2 s\n",
      "[1 100] loss: 0.581471 metric: 0.523490 time: 5.9 s\n",
      "[1 150] loss: 0.544226 metric: 0.563107 time: 5.9 s\n",
      "[1 200] loss: 0.532716 metric: 0.470588 time: 5.8 s\n",
      "[1 250] loss: 0.523140 metric: 0.537815 time: 6.0 s\n",
      "[1 300] loss: 0.518676 metric: 0.574257 time: 5.7 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 1]. loss: 0.503271 acc: 0.707081 f1: 0.505813 time: 42.1 s\n",
      "*****************************************************************\n",
      "save model...\n",
      "learning rate: 0.001000\n",
      "[2 50] loss: 0.499459 metric: 0.466019 time: 5.9 s\n",
      "[2 100] loss: 0.497131 metric: 0.606061 time: 5.9 s\n",
      "[2 150] loss: 0.476251 metric: 0.634146 time: 5.9 s\n",
      "[2 200] loss: 0.475933 metric: 0.513514 time: 5.9 s\n",
      "[2 250] loss: 0.472190 metric: 0.521008 time: 6.0 s\n",
      "[2 300] loss: 0.471910 metric: 0.607843 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 2]. loss: 0.486889 acc: 0.716046 f1: 0.518710 time: 41.9 s\n",
      "*****************************************************************\n",
      "save model...\n",
      "learning rate: 0.001000\n",
      "[3 50] loss: 0.467021 metric: 0.529412 time: 5.8 s\n",
      "[3 100] loss: 0.460489 metric: 0.589928 time: 5.9 s\n",
      "[3 150] loss: 0.443463 metric: 0.644628 time: 5.9 s\n",
      "[3 200] loss: 0.439640 metric: 0.537931 time: 5.9 s\n",
      "[3 250] loss: 0.446816 metric: 0.542373 time: 6.0 s\n",
      "[3 300] loss: 0.438952 metric: 0.614035 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 3]. loss: 0.483659 acc: 0.746661 f1: 0.536487 time: 42.0 s\n",
      "*****************************************************************\n",
      "save model...\n",
      "learning rate: 0.001000\n",
      "[4 50] loss: 0.446651 metric: 0.553191 time: 5.8 s\n",
      "[4 100] loss: 0.432613 metric: 0.640000 time: 5.9 s\n",
      "[4 150] loss: 0.428931 metric: 0.681481 time: 5.9 s\n",
      "[4 200] loss: 0.417548 metric: 0.571429 time: 5.9 s\n",
      "[4 250] loss: 0.430821 metric: 0.581818 time: 6.0 s\n",
      "[4 300] loss: 0.417459 metric: 0.690265 time: 5.7 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 4]. loss: 0.487615 acc: 0.761847 f1: 0.546616 time: 41.8 s\n",
      "*****************************************************************\n",
      "save model...\n",
      "learning rate: 0.001000\n",
      "[5 50] loss: 0.425210 metric: 0.576923 time: 5.9 s\n",
      "[5 100] loss: 0.404206 metric: 0.650794 time: 5.9 s\n",
      "[5 150] loss: 0.410435 metric: 0.686567 time: 5.9 s\n",
      "[5 200] loss: 0.388779 metric: 0.615385 time: 5.8 s\n",
      "[5 250] loss: 0.403572 metric: 0.596491 time: 6.0 s\n",
      "[5 300] loss: 0.391548 metric: 0.678261 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 5]. loss: 0.505147 acc: 0.773617 f1: 0.549952 time: 41.9 s\n",
      "*****************************************************************\n",
      "save model...\n",
      "learning rate: 0.001000\n",
      "[6 50] loss: 0.397477 metric: 0.631579 time: 5.9 s\n",
      "[6 100] loss: 0.378257 metric: 0.671875 time: 5.9 s\n",
      "[6 150] loss: 0.391293 metric: 0.770492 time: 5.9 s\n",
      "[6 200] loss: 0.360614 metric: 0.623188 time: 5.9 s\n",
      "[6 250] loss: 0.389565 metric: 0.571429 time: 6.0 s\n",
      "[6 300] loss: 0.368535 metric: 0.715596 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 6]. loss: 0.516978 acc: 0.764652 f1: 0.543151 time: 42.0 s\n",
      "*****************************************************************\n",
      "learning rate: 0.001000\n",
      "[7 50] loss: 0.371483 metric: 0.678899 time: 5.9 s\n",
      "[7 100] loss: 0.352132 metric: 0.771930 time: 6.0 s\n",
      "[7 150] loss: 0.369927 metric: 0.741935 time: 5.8 s\n",
      "[7 200] loss: 0.339612 metric: 0.641791 time: 5.9 s\n",
      "[7 250] loss: 0.359048 metric: 0.590164 time: 6.0 s\n",
      "[7 300] loss: 0.354288 metric: 0.719298 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 7]. loss: 0.544091 acc: 0.785753 f1: 0.547469 time: 41.9 s\n",
      "*****************************************************************\n",
      "learning rate: 0.001000\n",
      "[8 50] loss: 0.356650 metric: 0.638655 time: 5.9 s\n",
      "[8 100] loss: 0.349216 metric: 0.722689 time: 5.9 s\n",
      "[8 150] loss: 0.353403 metric: 0.796748 time: 5.9 s\n",
      "[8 200] loss: 0.336881 metric: 0.688525 time: 5.9 s\n",
      "[8 250] loss: 0.362704 metric: 0.606061 time: 6.0 s\n",
      "[8 300] loss: 0.335484 metric: 0.728814 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 8]. loss: 0.562177 acc: 0.763615 f1: 0.540867 time: 42.1 s\n",
      "*****************************************************************\n",
      "learning rate: 0.001000\n",
      "[9 50] loss: 0.330732 metric: 0.596774 time: 5.9 s\n",
      "[9 100] loss: 0.322974 metric: 0.747967 time: 5.9 s\n",
      "[9 150] loss: 0.340117 metric: 0.736842 time: 5.9 s\n",
      "[9 200] loss: 0.326492 metric: 0.676923 time: 5.9 s\n",
      "[9 250] loss: 0.331038 metric: 0.602941 time: 6.1 s\n",
      "[9 300] loss: 0.307174 metric: 0.765217 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 9]. loss: 0.578230 acc: 0.761115 f1: 0.537490 time: 42.1 s\n",
      "*****************************************************************\n",
      "learning rate: 0.001000\n",
      "[10 50] loss: 0.301184 metric: 0.654867 time: 5.9 s\n",
      "[10 100] loss: 0.301544 metric: 0.758065 time: 5.9 s\n",
      "[10 150] loss: 0.320458 metric: 0.753846 time: 5.9 s\n",
      "[10 200] loss: 0.300694 metric: 0.731707 time: 6.0 s\n",
      "[10 250] loss: 0.301486 metric: 0.644628 time: 6.1 s\n",
      "[10 300] loss: 0.290706 metric: 0.792453 time: 5.8 s\n",
      "Evaluating....\n",
      "*****************************************************************\n",
      "[epoch 10]. loss: 0.567974 acc: 0.684272 f1: 0.496646 time: 42.3 s\n",
      "*****************************************************************\n",
      "early stop at [10] epoch!\n"
     ]
    }
   ],
   "source": [
    "print_every = 50\n",
    "best_state = None\n",
    "max_metric = 0\n",
    "# model.to(DEVICE)\n",
    "def predict(model, data_dl, loss_func, device):\n",
    "    model.eval()\n",
    "    res_list = []\n",
    "    label_list = []\n",
    "    loss = 0\n",
    "    for text1, text2, label in data_dl:\n",
    "        text1 = text1.to(DEVICE)\n",
    "        text2 = text2.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        x1_mask, x2_mask = get_mask(text1, text2)\n",
    "        y_pred = model(text1, text2, x1_mask, x2_mask)\n",
    "        loss += loss_func(y_pred, label).data.cpu()\n",
    "        y_pred = y_pred.data.max(1)[1].cpu().numpy()\n",
    "        res_list.extend(y_pred)\n",
    "        label_list.extend(label.data.cpu().numpy())\n",
    "    acc = accuracy_score(res_list, label_list)\n",
    "    Precision = precision_score(res_list, label_list)\n",
    "    Recall = recall_score(res_list, label_list)\n",
    "    F1 = f1_score(res_list, label_list)\n",
    "    \n",
    "    return loss, (acc, Precision, Recall, F1)\n",
    "        \n",
    "def evaluate(model, txt1, txt2, x1_mask, x2_mask, y):\n",
    "    pred = model(txt1, txt2, x1_mask, x2_mask)\n",
    "    out_batch = pred.data.max(1)[1].cpu().numpy()\n",
    "    F1 = f1_score(out_batch, y)\n",
    "    return F1\n",
    "\n",
    "def training_termination(valid_result):\n",
    "    if len(valid_result) >= 4:\n",
    "        if valid_result[-1] < valid_result[-2] and \\\n",
    "            valid_result[-2] < valid_result[-3] and \\\n",
    "            valid_result[-3] < valid_result[-4]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "valid_iter.create_batches()\n",
    "valid_batch_num = len(list(valid_iter.batches))\n",
    "print_flush('start train...')\n",
    "train_iter.create_batches()\n",
    "batch_num = len(list(train_iter.batches))\n",
    "print_flush('batch number %d '%batch_num)\n",
    "valid_result = []\n",
    "for epoch in range(EPOCHES):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('learning rate: %.6f'% param_group['lr'])\n",
    "    epoch_begin = time()\n",
    "    total_loss = 0.0\n",
    "    train_iter.init_epoch()\n",
    "    batch_count = 0\n",
    "    batch_begin_time = time()\n",
    "    for text1, text2, label in train_dl:\n",
    "        model.train()\n",
    "        text1 = text1.to(DEVICE)\n",
    "        text2 = text2.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        x1_mask, x2_mask = get_mask(text1, text2)\n",
    "        y_pred = model(text1, text2, x1_mask, x2_mask)\n",
    "        loss = criterion(y_pred, label)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        if batch_count % print_every == 0:\n",
    "            metric = evaluate(model.eval(), text1, text2, x1_mask, x2_mask, label)\n",
    "            print_flush('[%d %d] loss: %.6f metric: %.6f time: %.1f s' %\n",
    "                  (epoch + 1, batch_count, total_loss / print_every, metric, time() - batch_begin_time))\n",
    "            total_loss = 0.0\n",
    "            batch_begin_time = time()\n",
    "#     scheduler.step()\n",
    "    print_flush(\"Evaluating....\")\n",
    "    loss, (acc, Precision, Recall, F1) = predict(model, valid_dl, criterion, DEVICE)\n",
    "    valid_result.append(F1)\n",
    "    print_flush('*'*65)\n",
    "    print_flush('[epoch %d]. loss: %.6f acc: %.6f f1: %.6f time: %.1f s'%(epoch+1, loss/valid_batch_num, acc, F1, time()-epoch_begin))\n",
    "    print_flush('*'*65)\n",
    "    if F1 > max_metric:\n",
    "        best_state = model.state_dict()\n",
    "        max_metric = F1\n",
    "        print_flush(\"save model...\")\n",
    "        torch.save(best_state, '../datasets/models/baseline_LSTM.pth')\n",
    "    epoch_begin = time()\n",
    "    if training_termination(valid_result):\n",
    "        print_flush(\"early stop at [%d] epoch!\" % (epoch+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
